{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e27685f",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add44fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python mediapipe sklearn matplotlib attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5738ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222e579",
   "metadata": {},
   "source": [
    "** 2. Keypoints using MP Holistic **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60c3c1",
   "metadata": {},
   "source": [
    "3. Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2890967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results, image_hight, image_width):\n",
    "    if results.pose_landmarks:\n",
    "        land_marks = [results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE], results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_PINKY],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_PINKY],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_INDEX],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_INDEX],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_THUMB],  results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_THUMB]]\n",
    "        x_1 = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width\n",
    "        y_1 = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_hight\n",
    "    else:\n",
    "        np.zeros(13*2)\n",
    "    pose = np.array([[(res.x * image_width)-x_1, (res.y * image_hight)-y_1] for res in land_marks]).flatten() if results.pose_landmarks else np.zeros(13*2)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "    #return np.concatenate([lh, rh])\n",
    "    #return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lebels = ['Bird', 'Bitter', 'Black', 'Book', 'Bread', 'Break', 'Caram', 'Chair', 'Clean', 'Come', 'Degrade', 'Door', 'Egg', 'Exercise', 'Exercise Book', 'Fate', 'February', 'Fish', 'Food', 'Good', 'Goodboy', 'Growth', 'Hearing_Impaired', 'January', 'Khoda Hafez', 'Large', 'Listen', 'March', 'Me', 'Meat', 'Mobile', 'More', 'Pencil', 'Picture', 'Procession', 'Quick', 'Remember', 'Rose Color', 'Salam', 'Short', 'Sit', 'Small', 'Snake', 'Table', 'Telephone', 'Thanks', 'Tiger', 'Together', 'Up', 'Wet']\n",
    "\n",
    "\n",
    "print(len(lebels))\n",
    "classes = np.array(lebels)\n",
    "print(classes)\n",
    "label_map = {label:num for num, label in enumerate(lebels)}\n",
    "\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03575cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### pre-processing #############################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATA_PATH = os.path.join('DataSet-50-W')\n",
    "sequence_length = 30\n",
    "\n",
    "#lebels = ['bird']\n",
    "#lebels = ['Bird', 'Bitter','Black','Book']\n",
    "\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(lebels)}\n",
    "\n",
    "print(label_map)\n",
    "\n",
    "\n",
    "def get_video_parts(video_path):\n",
    "    \"\"\"Given a full path to a video, return its parts.\"\"\"\n",
    "    parts = video_path.split(os.path.sep)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "\n",
    "    return train_or_test, classname, filename_no_ext, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_parts(video_path):\n",
    "    \"\"\"Given a full path to a video, return its parts.\"\"\"\n",
    "    parts = video_path.split(os.path.sep)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "\n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "\n",
    "#np.load('0.npy')\n",
    "\n",
    "DATA_PATH = os.path.join('DataSet-50-W')\n",
    "data_file = []\n",
    "\n",
    "sequence_length = 30\n",
    "sequence = 0\n",
    "s = 0\n",
    "i = 0\n",
    "j = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid_class in classes:\n",
    "    # Set mediapipe model \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        class_files = glob.glob(os.path.join(DATA_PATH, vid_class, '*.mp4'))\n",
    "        #print(class_files)\n",
    "        i += 1\n",
    "\n",
    "        for video_path in class_files:\n",
    "            print(video_path)\n",
    "            j += 1\n",
    "\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            property_id = int(cv2.CAP_PROP_FRAME_COUNT)\n",
    "            length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(\"The total frame number is {0}\".format(str(length)))\n",
    "            print(\"The property_id number is {0}\".format(str(property_id)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Get the parts of the file.\n",
    "            video_parts = get_video_parts(video_path)\n",
    "            print(video_parts)\n",
    "\n",
    "            train_or_test, classname, filename_no_ext, filename = video_parts\n",
    "            #print(classname)\n",
    "            #print(filename_no_ext)\n",
    "            #print(filename)\n",
    "\n",
    "            sequence += 1\n",
    "\n",
    "            #while cap.isOpened():\n",
    "            for frame_num in range(length):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "                print(frame)\n",
    "                s += 1\n",
    "                print(i)\n",
    "                print(j)\n",
    "                print(s)\n",
    "                print(\"################# Done  ########################################\")\n",
    "\n",
    "                #print(frame)\n",
    "                # Print nose coordinates.\n",
    "                image_hight, image_width, _ = frame.shape\n",
    "                print(image_hight)\n",
    "                print(image_width)\n",
    "\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                \n",
    "\n",
    "\n",
    "                                # NEW Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(filename, sequence), (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(500)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(filename, sequence), (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results, image_hight, image_width)\n",
    "                print(keypoints)\n",
    "                print(keypoints.shape)\n",
    "\n",
    "                npy_path = os.path.join(os.path.abspath(\".\"), DATA_PATH, classname, filename_no_ext, str(frame_num))\n",
    "\n",
    "                if not(os.path.exists(os.path.join(os.path.abspath(\".\"), DATA_PATH, classname, filename_no_ext))):\n",
    "                    os.mkdir(os.path.join(os.path.abspath(\".\"), DATA_PATH, classname, filename_no_ext))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step_size = 5\n",
    "sequences, labels = [], []\n",
    "for lebel in lebels:\n",
    "    class_files = glob.glob(os.path.join(DATA_PATH, lebel, '*.mp4'))\n",
    "    \n",
    "    for class_file in class_files:\n",
    "        video_parts = get_video_parts(class_file)\n",
    "\n",
    "        train_or_test, classname, filename_no_ext, filename = video_parts\n",
    "        \n",
    "        generated_files = glob.glob(os.path.join(DATA_PATH, lebel, filename_no_ext, '*.npy'))\n",
    "        #print(generated_files)\n",
    "        #print(generated_files[5])\n",
    "        \n",
    "        total_npy = len(generated_files)\n",
    "        print(\"The total_npy number is {0}\".format(str(total_npy)))\n",
    "        \n",
    "        j = 0\n",
    "        i = 0\n",
    "        step_size = int(((total_npy-sequence_length)+5)/5)\n",
    "        print(step_size)\n",
    "        #window = []\n",
    "        print(\"The Folder name is \"+ filename_no_ext)\n",
    "\n",
    "        \n",
    "        while(i < step_size): \n",
    "            window = []\n",
    "            for frame_num in range(j, j+sequence_length):\n",
    "                #print(frame_num)    \n",
    "                if j+30 <= total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)\n",
    "            i += 1\n",
    "            j += 5\n",
    "            print(j)\n",
    "            #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel]) \n",
    "               \n",
    "        # previous comment starts here\n",
    "        \"\"\"\n",
    "        \n",
    "        for frame_num in range(j, j+30):\n",
    "            #print(frame_num)    \n",
    "            if j+30 < total_npy:\n",
    "                print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                window.append(res)   \n",
    "\n",
    "            #i += 1\n",
    "            #j += 5\n",
    "            print(j)\n",
    "            #generated_files = generated_files[i * 5] \n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[lebel]) \n",
    "\n",
    "        j += 5 \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "\n",
    "\n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)   \n",
    "                else:\n",
    "                    break\n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel])     \n",
    "        \n",
    "        j += 5  \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "\n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)   \n",
    "                else:\n",
    "                    break\n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel])   \n",
    "        \n",
    "        j += 5 \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "        \n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)  \n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "\n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel]) \n",
    "\n",
    "        \n",
    "        j += 5  \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "\n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)  \n",
    "                else:\n",
    "                    break     \n",
    "\n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel])   \n",
    "        \n",
    "        j += 5  \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "        \n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res) \n",
    "                else:\n",
    "                    break      \n",
    "\n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel]) \n",
    "        \n",
    "        j += 5 \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "\n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)  \n",
    "                else:\n",
    "                    break      \n",
    "\n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel])   \n",
    "        \n",
    "        j += 5  \n",
    "        i += 1\n",
    "        if i < step_size:\n",
    "        \n",
    "            for frame_num in range(j, j+30):\n",
    "                #print(frame_num)    \n",
    "                if j+30 < total_npy:\n",
    "                    print(\"The frame number is {0}\".format(str(frame_num)))\n",
    "                    res = np.load(os.path.join(DATA_PATH, lebel, filename_no_ext, \"{}.npy\".format(frame_num)))\n",
    "                    window.append(res)   \n",
    "                else:\n",
    "                    break \n",
    "                #i += 1\n",
    "                #j += 5\n",
    "                print(j)\n",
    "                #generated_files = generated_files[i * 5] \n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[lebel]) \n",
    "        #previous comment ends here\n",
    "        \"\"\"\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "print(np.array(sequences).shape)\n",
    "print(np.array(labels).shape)\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(sequences)\n",
    "print(X)\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5497c75",
   "metadata": {},
   "source": [
    "############# Build and Train LSTM Neural Network ###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c904836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Lstm with attention ---------------------------\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input, metrics\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Dummy data. There is nothing to learn in this example.\n",
    "    num_samples, time_steps, input_dim, output_dim = 2159, 30, 1556, 4\n",
    "    #data_x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
    "    #data_y = np.random.uniform(size=(num_samples, output_dim))\n",
    "\n",
    "    # Define/compile the model.\n",
    "    model_input = Input(shape=(time_steps, input_dim))\n",
    "    x = LSTM(128, return_sequences=True)(model_input)\n",
    "    #x = LSTM(128, return_sequences=True, activation='relu')(x)\n",
    "    x = Attention(units=64)(x)\n",
    "    #x = LSTM(64, activation='relu')(x)\n",
    "    x = Dense(64, activation = 'relu')(x)\n",
    "    x = Dense(classes.shape[0], activation='softmax')(x)\n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    c_backs = [callbacks.EarlyStopping(patience=40, \\\n",
    "       restore_best_weights=True)]\n",
    "    \n",
    "    rms = optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    model.compile( loss = \"categorical_crossentropy\", \n",
    "                optimizer = rms, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    #model.compile(loss='mae', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # train.\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)\n",
    "\n",
    "    # test save/reload model.\n",
    "    pred1 = model.predict(X_train)\n",
    "    model.save('lstm+attention_bsl_model.h5')\n",
    "    model_h5 = load_model('lstm+attention_bsl_model.h5', custom_objects={'Attention': Attention})\n",
    "    pred2 = model_h5.predict(X_train)\n",
    "    np.testing.assert_almost_equal(pred1, pred2)\n",
    "    print('Success.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efcc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------BiLstm with attention ---------------------------\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input, metrics, callbacks, optimizers\n",
    "from tensorflow.keras.layers import Bidirectional, Dense, LSTM, GRU\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Dummy data. There is nothing to learn in this example.\n",
    "    num_samples, time_steps, input_dim, output_dim = 16252, 30, 1556, 4\n",
    "    #data_x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
    "    #data_y = np.random.uniform(size=(num_samples, output_dim))\n",
    "\n",
    "    # Define/compile the model.\n",
    "    model_input = Input(shape=(time_steps, input_dim))\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(model_input)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, activation='relu'))(x)\n",
    "    x = Attention(units=64)(x)\n",
    "    #x = Bidirectional(LSTM(64, return_sequences=True, activation='relu'))(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(classes.shape[0], activation='softmax')(x)\n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    \n",
    "    c_backs = [callbacks.EarlyStopping(patience=40, \\\n",
    "       restore_best_weights=True)]\n",
    "    \n",
    "    rms = optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    model.compile( loss = \"categorical_crossentropy\", \n",
    "                optimizer = rms, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    #model.compile(loss='mae', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # train.\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150)\n",
    "\n",
    "    # test save/reload model.\n",
    "    pred1 = model.predict(X_train)\n",
    "    model.save('BiLSTM+attention_bsl_model_w.h5')\n",
    "    model_h5 = load_model('BiLSTM+attention_bsl_model.h5_w', custom_objects={'Attention': Attention})\n",
    "    pred2 = model_h5.predict(X_train)\n",
    "    np.testing.assert_almost_equal(pred1, pred2)\n",
    "    print('Success.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14370bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------GRU with attention ---------------------------\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input, metrics\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Dummy data. There is nothing to learn in this example.\n",
    "    num_samples, time_steps, input_dim, output_dim = 2159, 30, 1556, 4\n",
    "    #data_x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
    "    #data_y = np.random.uniform(size=(num_samples, output_dim))\n",
    "\n",
    "    # Define/compile the model.\n",
    "    model_input = Input(shape=(time_steps, input_dim))\n",
    "    x = GRU(128, return_sequences=True)(model_input)\n",
    "    #x = LSTM(128, return_sequences=True, activation='relu')(x)\n",
    "    x = Attention(units=64)(x)\n",
    "    #x = LSTM(64, activation='relu')(x)\n",
    "    x = Dense(64, activation = 'relu')(x)\n",
    "    x = Dense(classes.shape[0], activation='softmax')(x)\n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    c_backs = [callbacks.EarlyStopping(patience=40, \\\n",
    "       restore_best_weights=True)]\n",
    "    \n",
    "    rms = optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    model.compile( loss = \"categorical_crossentropy\", \n",
    "                optimizer = rms, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    #model.compile(loss='mae', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # train.\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)\n",
    "\n",
    "    # test save/reload model.\n",
    "    pred1 = model.predict(X_train)\n",
    "    model.save('GRU+attention_bsl_model.h5')\n",
    "    model_h5 = load_model('GRU+attention_bsl_model.h5', custom_objects={'Attention': Attention})\n",
    "    pred2 = model_h5.predict(X_train)\n",
    "    np.testing.assert_almost_equal(pred1, pred2)\n",
    "    print('Success.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------BiGRU with attention ---------------------------\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Input, metrics, callbacks, optimizers\n",
    "from tensorflow.keras.layers import Bidirectional, Dense, LSTM, GRU\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Dummy data. There is nothing to learn in this example.\n",
    "    num_samples, time_steps, input_dim, output_dim = 16252, 30, 1556, 4\n",
    "    #data_x = np.random.uniform(size=(num_samples, time_steps, input_dim))\n",
    "    #data_y = np.random.uniform(size=(num_samples, output_dim))\n",
    "\n",
    "    # Define/compile the model.\n",
    "    model_input = Input(shape=(time_steps, input_dim))\n",
    "    x = Bidirectional(GRU(64, return_sequences=True))(model_input)\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, activation='relu'))(x)\n",
    "    x = Attention(units=64)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(classes.shape[0], activation='softmax')(x)\n",
    "    model = Model(model_input, x)\n",
    "    \n",
    "    c_backs = [callbacks.EarlyStopping(patience=40, \\\n",
    "       restore_best_weights=True)]\n",
    "    \n",
    "    rms = optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "    model.compile( loss = \"categorical_crossentropy\", \n",
    "                optimizer = rms, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    #model.compile(loss='mae', optimizer='adam',  metrics=['categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # train.\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs= 200, callbacks = c_backs)\n",
    "    \n",
    "    model.save('BiGRU+attention_bsl_model_w.h5')\n",
    "\n",
    "    # test save/reload model.\n",
    "    pred1 = model.predict(X_train)\n",
    "    model.save('BiGRU+attention_bsl_model_w.h5')\n",
    "    model_h5 = load_model('BiGRU+attention_bsl_model_w.h5', custom_objects={'Attention': Attention})\n",
    "    pred2 = model_h5.predict(X_train)\n",
    "    np.testing.assert_almost_equal(pred1, pred2)\n",
    "    print('Success.')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bcce6",
   "metadata": {},
   "source": [
    "################### Evaluation using Confusion Matrix and Accuracy ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "\n",
    "model_h5 = load_model('BiGRU+attention_bsl_model.h5', custom_objects={'Attention': Attention})\n",
    "yhat = model_h5.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "print(multilabel_confusion_matrix(ytrue, yhat))\n",
    "print(accuracy_score(ytrue, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295ffe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
